\documentclass[9pt]{extarticle}
\usepackage{extsizes}
\usepackage[utf8]{inputenc}
\usepackage{mathtools,amssymb}
\usepackage{lipsum}
\usepackage{hyperref}
\usepackage{layout}
\usepackage{geometry}
\usepackage{listings}
\usepackage{color}
\usepackage{pdfpages}
\newcommand*{\vertbar}[1][10ex]{\rule[-1ex]{0.5pt}{#1}}
\newcommand*{\horzbar}{\rule[.5ex]{2.5ex}{0.5pt}}
\newcommand{\norm}[2]{\left\lVert#1\right\rVert_#2}
\newcommand{\abs}[1]{\lvert#1\rvert}

\title{CME308: Stochastic Methods in Engineering}
\author{Erich Trieschman}
\date{2022 Spring quarter}

\newcommand{\userMarginInMm}{5}
\geometry{
 left=\userMarginInMm mm,
 right=\userMarginInMm mm,
 top=\userMarginInMm mm,
 bottom=\userMarginInMm mm,
 footskip=3mm}

\newcommand*\circled[1]{\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {#1}}}}
\newcommand*\bspace{$\; \bullet \;$}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdfpagemode=FullScreen,
}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
    
\lstset{frame=tb, language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3}


\begin{document}
% \maketitle
\section{Probability cheat sheet}
PLACEHOLDER. INCLUDE
\begin{itemize}
    \item MGFs
\end{itemize}

\section{Markov chains}
\subsection{Example: Reservoir storage}
\textbf{Given:} $S_{n+1} = S_n +Z_{n+1} - (aS_{n+1}^b)$, $Z_i \sim f_z(\cdot)$. \textbf{Want:} $P_x(S_1 \leq y)$
\begin{align*}
    P_x(S_1 \leq y) &= P_x(g(S_1) \leq g(y)) \textrm{, recognizing $g(x) = x + ax^b$ monotone}\\
    &= P_x(S_1 + aS_1^b \leq y + ay^b) = P_x(x + Z_1 \leq y + ay^b) = F_z(y + ay^b - x)\\
    p(x,y) &= \frac{d}{dy}F_z(y + ay^b - x) = f_z(y + ay^b - x)*(1 + aby^{b-1}), \;\;\; P(x,B) = \int_Bf_z(y + ay^b - x)*(1 + aby^{b-1})dy
\end{align*}

\subsection{Example: Congestion modeling}
\textbf{Given:} Markov chain $W = (W_n:n\geq 0)$, $W_{n+1} = [W_n + Z_{n+1}]^+$, $Z_i \sim f_z(\cdot)$. \textbf{Want:} Transition kernel.\\
\begin{align*}
    P_x(W_1 \leq y) &= P_x([x + Z_1]^+ \leq y) = P_x(x + Z_1 \leq y) = F_z(y-x) \textrm{, second to last step since } y \geq 0\\
    \textrm{When } y = 0: &P_x(W_1 = 0) = P(W_1 \leq 0) = F_z(-x) \textrm{(point mass at $y=0$)}; \;\;\; \textrm{When } y > 0: \frac{d}{dy}P_x(W_1 \leq y) = f_z(y-x)\\
    P(x,dy) &= F_z(-x)\delta_0(dy) + f_z(y-x)dy, \;\;\; P(X, B) = F_z(x)\delta_0(B) + \int_Bf_x(y-x)dy
\end{align*}

\subsection{Example: Autogregressive modeling}
For $X_{n+1} = a_0X_n + c + \epsilon_{n+1}, \, \epsilon \sim N(0,\sigma^2)$, $L(a_0,c,\sigma^2 \mid X) = \prod_{j=0}^{n-1}(\frac{1}{\sqrt{2\pi}\sigma})\exp(\frac{-1}{2\sigma^2}(X_{j+1} - a_0X_j - c)^2)$; $Cov(X_{n+1}, X_n) = Cov(a_0X_n + c+ \epsilon, X_n) = a_0var(X_n)$


\section{Likelihood and estimation}
\subsection{Estimating equations}
Objective is to postulate $g(\cdot)$ such that $E_{\theta_1}g(\theta_2, X_1) = 0 \Longleftrightarrow \theta_1 = \theta_2$. We can estimate $\theta$ with the root, $\hat{\theta}$, of the equation $\frac{1}{n}\sum_{i=1}^ng(\hat{\theta}, X_i) = 0$. Estimating equations are a generalization of Method of Moments ($g(\theta, x) = E_\theta k(X_1) - k(x)$) and Maximum likelihood estimators ($g(\theta, x) = \frac{\nabla_\theta f(\theta, x)^T}{f(\theta, x)}$)\\
Assume we've established that $\hat{\theta} = \hat{\theta}_n \overset{p}{\longrightarrow} \theta^*$ (consistent), then
\begin{align*}
    \frac{1}{n}\sum_{i=1}^ng(\hat{\theta}, X_i) &- \frac{1}{n}\sum_{i=1}^ng(\theta^*, X_i) = - \frac{1}{n}\sum_{i=1}^ng(\theta^*, X_i)\\
    \frac{1}{n}\sum_{i=1}^ng(\xi_n, X_i)(\hat{\theta} - \theta^*) &= - \frac{1}{n}\sum_{i=1}^ng(\theta^*, X_i) \textrm{, by Taylor expansion (Mean Value Theorem)}\\
    \frac{1}{n}\sum_{i=1}^ng(\xi_n, X_i)\sqrt{n}(\hat{\theta} - \theta^*) &= \frac{-1}{\sqrt{n}}\sum_{i=1}^ng(\theta^*, X_i) \textrm{, where } \frac{1}{n}\sum_{i=1}^ng(\xi_n, X_i) \overset{p}{\longrightarrow} E_{\theta^*}g'(\theta^*, X_1) \textrm{, and } \frac{-1}{\sqrt{n}}\sum_{i=1}^ng(\theta^*, X_i) \overset{d}{\longrightarrow} \sigma N(0,1), \, \sigma^2 = E_{\theta^*}[g(\theta^*, X_1)^2]\\
    \sqrt(n)(\hat{\theta} - \theta^*) &\overset{d}{\longrightarrow} \frac{\theta}{E_{\theta^*}g'(\theta^*, X_1)}N(0,1) \textrm{, by Slutsky's Lemma}
\end{align*}


\subsection{Example: Markov chain parameter estimation}
Given: $X_n = \beta n + W_n$, $W_n = \rho W_{n-1} + Z_n$, $Z_i \sim N(\mu, \sigma^2) iid rvs$\\
Trick: Rearrange everything in terms of $Z_i: Z_n = W_n - \rho W_{n-1} \Longrightarrow Z_n = X_n - \beta n - \rho (X_{n-1} - \beta(n-1))$
\begin{align*}
    L = \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}} \exp(\frac{-1}{2\sigma^2} (Z_n - \mu)^2) = \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}} \exp(\frac{-1}{2\sigma^2} (X_n - \beta n - \rho (X_{n-1} - \beta(n-1)) - \mu)^2) \Longrightarrow \log L = \textrm{const} - \frac{1}{2}(2-\rho)^2 \Longrightarrow \hat{\rho} = 2
\end{align*}

\subsection{Example: Markov chain parameter estimation}
\textbf{Given:} $(X_j: 0 \leq j \leq n)$ observed path for finite state Markov chain. $P(\theta) = (P(\theta, x, y):w, y \in S)$ transition matrix depending on unknown param. $P(\theta)$ infinetely differentiable in $\theta$
\textbf{Want:} Likelihood, MLE, Martingale CLT
\begin{align*}
    L(\theta \mid X) &= \prod_{j=1}^n P(\theta, X_{j-1}, X_j) \textrm{, by Markov property} \Longrightarrow l(\theta \mid X) = \log L(\theta \mid X) = \sum_{j=1}^n \log P(\theta, X_{j-1}, X_j)\\
    \frac{d}{d\theta}l(\theta \mid X) &= \sum_{i=1}^n \frac{\frac{d}{d\theta}P(\theta, X_{i-1}, X_i)}{P(\theta, X_{i-1}, X_i)} \Longrightarrow \hat{\theta} \textrm{ is solution to } \sum_{i=1}^n \frac{\frac{d}{d\theta}P(\hat{\theta}, X_{i-1}, X_i)}{P(\hat{\theta}, X_{i-1}, X_i)} = 0
\end{align*}
\textbf{Martingale CLT:} First show its a martingale, then use CLT
\begin{align*}
    M &= (M_n = f(X_{n-1}, X_n): n \geq 0) \textrm{ adapted to } X = (X_n : n\geq 0) \textrm{ with Martingale difference, } D_i = \frac{\frac{d}{d\theta}P(\theta, X_{i-1}, x_i)}{P(\theta, X_{i-1}, x_i)}\\
    X \textrm{ stationary } &\Longrightarrow D_i := (P'/P)(\theta, X_{i-1}, X_i) \textrm{ stationary ergotic sequence}\\
    E[D_i] &= \int \frac{\frac{d}{d\theta}P(\theta, X_{i-1}, x_i)}{P(\theta, X_{i-1}, x_i)} P(\theta, X_{i-1}, x_i)dx_i = \int \frac{d}{d\theta}P(\theta, X_{i-1}, x_i)dx_i = \frac{d}{d\theta} 1 = 0 \\
    EM_n &= E[M_0 + \sum_i D_i] = E[M_0] + \sum_i E[D_i] = E[M_0] < \infty\\
    E[M_{n+1} \mid X_0, \dots, X_n] &= E[M_n + \frac{\frac{d}{d\theta}P(\theta, X_{i-1}, x_i)}{P(\theta, X_{i-1}, x_i)} \mid X_0, \dots, X_n] = M_n + 0\\
    \frac{1}{\sqrt{n}}M_n &\overset{d}{\rightarrow} \sigma N(0,1) \textrm{, where } \sigma^2 = E[D_1^2] = E\left [ \left (\frac{\frac{d}{d\theta}P(\theta, X_{i-1}, x_i)}{P(\theta, X_{i-1}, x_i)}\right )^2 \right ]
\end{align*}

\subsection{Example: Kernel density estimation for derivative}
\textbf{Kernel density estimation:} Estimate unknown density, $f^*(x)$ from 1D iid data, $X_1, \dots, X_n$ with a normal (or other kernel) function about each point, that's then summed up: $f_n(x)
= \frac{1}{n}\sum_{i=1}^n\frac{1}{h}\phi(\frac{x - X_i}{h})$ \bspace \textbf{Equation derivation:} At each point, $X_i$, smooth using density $N(X_i, h^2)$: $P(N(X_i, h^2)\leq y) = P(N(0,1) \leq (\frac{y-X_i}{h})) = \Phi(\frac{y-X_i}{h}) \Longrightarrow \frac{d}{dy}\Phi(\frac{y-X_i}{h}) = \phi(\frac{y-X_i}{h}) * \frac{1}{h}$\\
\textbf{Objective:} derive density estimator, derive expressions for bias and variance of estimator, choose optimal bandwidth, $h^*$. Recall: Here we want MSE = $var + bias^2$ to not explode so ultimately we choose $h^*$ such that $O(var) = O(bias^2)$.
\begin{align*}
    \frac{d}{dx} f_n(x) &= \frac{1}{n}\sum_{i=1}^n\frac{1}{h}\frac{d}{dx}\phi(\frac{x - X_i}{h})\\
    E[\frac{d}{dx} f_n(x)] &= \frac{1}{h}E[\frac{d}{dx}\phi(\frac{x - X_1}{h})] = \frac{1}{h}\int \frac{d}{dx}\phi(\frac{x - y}{h})  f^*(y) dy = \frac{1}{h}\int \frac{1}{h}\phi'(z)  f^*(x - zh) (-h) dz \textrm{, for } zh = x - y\\
    &= \frac{-1}{h} \int \phi'(z)[f(x) - zhf'(x) + \frac{(xh)^2}{2!}f''(x) - \frac{(zh)^3}{3!}f'''(x) + O(h^3)]dz\\
    &= \frac{-1}{h} f(x)\int\phi'(z)dz + f'(x)\int z\phi'(z)dz - \frac{h}{2} f'''(x)\int z^2\phi'(z)dz + \frac{(h)^2}{3!}\int z^3 \phi'(z) dz + O(h^2)\\
    &= \frac{-1}{h} f(x) * 0 + f'(x) * 1 - \frac{h}{2} f'''(x) * 0 + \frac{h^2}{3!} * \frac{1 * 4!}{2^2 * 2} + O(h^2) \textrm{, where } \phi'(x) = x\phi(x)\\
    E[\frac{d}{dx} f_n(x)] - \frac{d}{dx} f^*(x) &= \frac{h^2}{2}f'''(x) + O(h^2) = O(h^2)
\end{align*}
\begin{align*}
    Var(\frac{d}{dx}f_n(x)) &= \frac{1}{nh^2}Var(\frac{d}{dx}\phi(\frac{x - X_1}{h})) = \frac{1}{nh^2} E[(\frac{d}{dx}\phi(\frac{x - X_1}{h}))^2] - \frac{1}{nh^2}[E(\frac{d}{dx}\phi(\frac{x - X_1}{h}))]^2\\
    &= \frac{1}{nh^2} E[\frac{1}{h^2}\phi'^2(\frac{x - X_1}{h})] - \frac{1}{nh^2} * (O(h^2))^2 = \frac{1}{nh^2} \frac{1}{h^2} \int \phi'(z)^2f^*(x - zh)(-h)dz - \frac{1}{nh^2} * (O(h^2))^2\\
    &= \frac{1}{nh^2} \frac{-1}{h} \int z^2 \phi^2(z)[f^*(x) - O(h)]dz - \frac{1}{nh^2} * (O(h^2))^2 = O(\frac{1}{nh^3}) - O(h^2) = O(\frac{1}{nh^3})\\
    O(var) &\approx O(bias^2) \Longrightarrow O(\frac{1}{nh^3}) \approx O(h^4) \Longrightarrow h = O(n^{-1/7}) \Longrightarrow MSE = O(n^{-2/7})
\end{align*}

\section{First transition analysis}
Stationary: $E[f(X_{n+1}, \dots) \mid X_n = x] = E[f(X_1, \dots) \mid X_0 = x] = E_x[f(X_1, \dots)]$
\subsection{Example: Expectation of hitting time}
Compute: $E_xT_A$, $x\notin A$, $T_A = \inf\{n\geq 0 : X_n \in A\}$\\
When $x \in A, E_xT_A = 0$. Otherwise:
\begin{align*}
    &E_xT_A = 1 + E_x[T_A - 1] = 1 + \sum_{y\in A} E_x[T_A - 1 \mid X_1 = y]P_x(X_1 = y) + \sum_{y\notin A} E_x[T_A - 1 \mid X_1 = y]P_x(X_1 = y) = 1 + 0 + \sum_{y\notin A} E_y(T_A)P_x(X_1 = y)\\
    &E_x[T_{A-1} \mid X_1 = y] = E_x[\sum_{j=1}^{T_{A-1}} 1 \mid X_1 = y] =  E_x[\sum_{j=1}^\infty\mathbb{I}\{j < T_A\} \mid X_1 = y] = E_x[\sum_{j=1}^\infty \mathbb{I}\{X_0 \notin A, \dots, X_j \notin A\} \mid X_1 = y]\\
    &E_x[T_{A-1} \mid X_1 = y] = E_x[\sum_{j=1}^\infty \mathbb{I}\{X_1 \notin A, \dots, X_j \notin A\} \mid X_1 = y] = E_y[\sum_{j=0}^\infty \mathbb{I}\{X_1 \notin A, \dots, X_{j-1} \notin A\}] = E_y[\sum_{j=1}^\infty \mathbb{I}\{X_0 \notin A, \dots, X_{j} \notin A\}] = E_yT_A\\
    &u = e + Bu \textrm{, where } u = \{E_xT_X\}_{x \in A^c}, B = \{P_{x,y}\}_{(x, y) \in A^c \times A^c}
\end{align*}

\subsection{Example: Expectation of reward}
Given: $S$ discrete finite, $u(i) = E_i[\exp(-\sum_{n=0}^{T_{A-1}}\rho(X_n))r(X_{T_A})]$, $X_n$ Markov chain, $T_A$ hitting time\\
When $i \in A$, then $T_A = 0, u(i) = E_i[\exp(0)r(X_0)] = r(i)$. Otherwise:
\begin{align*}
    u(i) &= \exp(-p(i))E_i[\exp(-\sum_{n=1}^{T_{A-1}}\rho(X_n))r(X_{T_A})] = \exp(-p(i)) \sum_{j\in S} E_i[\exp(-\sum_{n=1}^{T_{A-1}}\rho(X_n))r(X_{T_A}) \mid X_1 = j]P_i(X_1 = j)\\
    &= \exp(-p(i)) \sum_{j\in A} E_i[\exp(-\sum_{n=1}^{T_{A-1}}\rho(X_n))r(X_{T_A}) \mid X_1 = j]P_i(X_1 = j) + \exp(-p(i)) \sum_{j\notin A} E_i[\exp(-\sum_{n=1}^{T_{A-1}}\rho(X_n))r(X_{T_A}) \mid X_1 = j]P_i(X_1 = j)\\
    &= \exp(-p(i)) \sum_{j\in A} E[r(X_1)\mid X_1 = j]P_i(X_1 = j) + \exp(-p(i)) \sum_{j\notin A} u(j)P(i,j) = \exp(-p(i)) \sum_{j\in A} r(j)P(i,j) + \exp(-p(i)) \sum_{j\notin A} u(j)P(i,j)\\
    u &= b + Ku \textrm{, where } b_i = exp(-p(i))\sum_{j\in A}r(j)P(i,j), K(i,j) = exp(-p(i))P(i,j)
\end{align*}

\section{Infinite horizon stochastic control}
\textbf{Objective:} Find optimal control $A^* = (A_n^*: n \geq 0)$ for objective $\max_{(A_n:n\geq0)}E_x\sum_{n=1}^\infty \exp(-\alpha n)r(X_n, A_n)$\\
\textbf{Solution:} Let $v(x) = \max_{(A_n:n\geq0)}E_x\sum_{n=1}^\infty \exp(-\alpha n)r(X_n, A_n)$\\
\textbf{By first transition analysis:} $v(x) = \max_{a \in \mathcal{A}(x)}[r(x,a) + \exp(-\alpha)\sum_yP_a(x,y)v(y)] = \max_{a \in \mathcal{A}(x)}\{r(x,a) + \exp(-\alpha)E[v(X_1) \mid X_0 = x, A_0 = a]\}$\\
\textbf{Solution approach 1 - Fixed point equation:} Notice this is a solution to the fixed point equation $v = Tv$, where $(Tu)(x) =\max_{a \in \mathcal{A}(x)}[r(x,a) + \exp(-\alpha)\sum_yP_a(x,y)u(y)]$. 1 Choose any $v_0$, 2) iterate $v_n = Tv_{n-1}$, 3), if $v_n \longrightarrow v_\infty$ then $v_\infty$ is solution. Convergence guaranteed with contractive property: $\norm{Tv_n - Tv_{n-1}}{\infty} \leq \exp(-\alpha)\norm{v_n - v_{n-1}}{\infty}$\\
\textbf{Solutions approach 2 - Linear program:} $\min_v \sum_xv(x) \,\,\, s.t., v(x) \geq r(x,a) + \exp(-\alpha)\sum_yP_a(x,y)v(y)$


\subsection{Example: Optimal stopping time}
\textbf{Given:} reward function $r: \{0, \dots, m\} \rightarrow \mathbb{R}_+$, $(X_n:n \geq 0)$ has transition probabilities $P(x,y) = 1/2, \, x \in \{1, \dots, m-1\}, y\in \{0, \dots, m\}$, $P(0,0) = P(m,m) = 1$\\
\textbf{Optimality equation (HJB equation):}
\begin{align*}
    v(x) = \sup_TE_xr(X_T) = \max\{\textrm{stop, continue}\} = \max(r(x), \frac{1}{2}(v(x-1) + v(x+1))), \, x \in \{1, \dots, m-1\}; \,\, v(0) = r(0),\,\, v(m) = r(m)
\end{align*}
Let $r(m) = 0$ and $r(x) = x$ otherwise. Compute \textbf{value function:} must be unique, using intuition you can claim it is $v(x) = x$. Given this, $v(x) = \frac{1}{2}(v(x-1) + v(x+1))$ for $x \leq m-1$. Hence, optimal stopping time is immediately if you are at $m-1$ or indifferent otherwise.

\subsection{Example: Optimal stopping time}
\textbf{Given:} $X = (X_n : n\geq 0)$, finite state, $P = (P(x,y):x,y \in S)$\\
\textbf{Want:} $T$ to maximize $E_x \sum_{j=1}^{T-1} \exp(-\alpha j)r(X_j) + \exp(-\alpha T)w(X_T)$
\begin{align*}
    v^*(x) = \sup_TE_x\sum_{j=1}^{T-1} \exp(-\alpha j)r(X_j) + \exp(-\alpha T)w(X_T) \textrm{, is finite valued and should satisfy } v(x) = max\{w(x), r(x) + \exp(-\alpha)\sum_yP(x,y)v(y)\}
\end{align*}
\begin{align*}
    \textrm{\textbf{Solution 1, Linear program: }}& \min_{v^*(x)} \sum_{x\in S}v(x) \textrm{  s.t., } v(x) \geq w(x), \,\, v(x) \geq r(x) + \exp(-\alpha)\sum_yP(x,y)v(y)\\
    \textrm{\textbf{Solution 2, Value iteration: }}& (Ru)(x) =  max\{w(x), r(x) + \exp(-\alpha)\sum_yP(x,y)v(y)\} \textrm{, choose $v_0$ and iterate; guaranteed convergence}
\end{align*}


\section{Martingales}
\textbf{Martingale definition:} A martingale $(M_n : n \geq 0)$ is adapted to $(Z_n : N\geq 0)$ if 1) Adaptedness: for each $n \geq 0$ there exists function $f_n(\cdot)$ such that $M_n = f_n(X_0, \dots, X_n)$, 2) $E\abs{M_n} < \infty$, 3) $E[M_{n+1} \mid X_0, \dots, X_n] = M_n$ \bspace $D_n = M_n - M_{n-1}$ \bspace $M_n = M_0 + \sum_iD_i$ \bspace $ED_i = 0$ \bspace $Cov(D_i, D_j) = ED_iD_j = 0, i\neq j$ \bspace $Cov(M_0, D_i) = 0$ \bspace $Var(M_n) = Var(M_0) + \sum_iVar(D_i)$\\
\textbf{Martingale convergence:} $\frac{1}{n}M_n \overset{a.s.}{\rightarrow} 0$\\
\textbf{Martingale CLT:} If a martingale $(M_n : n \geq 0)$ adapted to $(Z_n:N\geq 0)$ is square integrable, then $\frac{1}{\sqrt{n}}M_n \overset{d}{\rightarrow} \sigma N(0,1)$ \bspace $\sigma^2 = Var(D_1) = E(D_1^2)$

\subsection{Example: Demonstrate martingale sequence}
\textbf{Given:} $S_n = Z_1 + \dots + Z_n$, $Z_i$ iid, $EZ_1^2 < \infty$, $EZ_1 = 0$, $M_n = S_n^2 - n\sigma^2$\\
\textbf{Adaptedness condition} exists by definition. \textbf{Boundedness condition} holds since $\sigma^2 < \infty$, $EZ_1 = 0$. \textbf{Expectation of $M_{n+1}$:} $E(M_{n+1} \mid Z_0,\dots,Z_n) = E[(S_n + Z_{n+1})^2 - (n+1)\sigma^2 \mid Z_0,\dots,Z_n] = S_n^2 + 2S_nE[Z_{n+1} \mid Z_0,\dots,Z_n] + E[Z_{n+1}^2\mid Z_0, \dots, Z_n] - n\sigma^2 - \sigma^2 = S_n^2 + 2S_n*0 + \sigma^2 - n\sigma^2 - \sigma^2 = S_n^2 - n\sigma^2 = M_n$

\subsection{Example: Demonstrate martingale sequence}
\textbf{Given:} $f:S\longrightarrow \mathbb{R}$, bounded and $Pf = f$, one-step transition matrix, $X_n$ a Markov sequence. \textbf{Want:} show $f(X_n)$ is a martingale sequence. \textbf{Adaptedness condition} exists by definition. \textbf{Boundedness condition} holds by boundedness of $f$. \textbf{Expectation of $M_{n+1}$:} $E[f(X_{n+1})\mid X_0,\dots,X_n] = \sum_{y\in S}f(y)P(X_{n+1}=y \mid X_0,\dots,X_n) = \sum_{y\in S}F(y)P(X_n,y) = \large [Pf\large ]_{X_n} = f(X_n)$

\subsection{Example: Demonstrate martingale difference sequence}
\textbf{Given:} $g: S \longrightarrow \mathbb{R}$ bounded and $D_i = g(X_i) - E[g(X_i)\mid X_{i-1}]$. \textbf{Show:} This is a martingale difference adapted to $X = (X_n:n\geq 0)$\\
\textbf{Adaptedness condition} exists by definition. \textbf{Boundedness condition} holds by definition of $g$. \textbf{Zero expectation conditional on the past:} $E[D_n+1 \mid X_0, \dots, X_n] = E[g(X_{n+1})\mid X_0, \dots, X_n] - E[E[g(X_{n+1})\mid X_n] \mid X_0, \dots, X_n] \Longleftrightarrow E[g(X_{n+1})\mid X_n] - E[g(X_{n+1})\mid X_n] = 0$ 



\section{Bayesian statistics}

\subsection{Example: posterior distribution}
\textbf{Want:} posterior distribution of probability of success, $p$. \textbf{Given:} $\pi(p) \sim Beta(\alpha, \beta)$, $k$ successes in $n$ experiments\\
$\pi(p \mid X) \propto \pi(p)L(p \mid X) \propto p^{\alpha-1}(1-p)^{\beta - 1}p^k(1-p)^{n-k} = p^{\alpha + k - 1}(1-p)^{\beta + n - k - 1} \propto Beta(\alpha + k, \beta + n - k)$


\subsection{Example: posterior distribution}
Given: iid data, $X_1, \dots, X_n$, follows Poisson: $f(x) = \lambda e^{-\lambda x}$, $\lambda > 0$, unknown; prior on $\lambda$ follows Gamma with shape param ($\alpha$) 3 and rate ($\beta$) param 2$\pi(\lambda) = 4\lambda^2e^{-2\lambda}$
Aside: Gamma rv, $g(x) = \frac{\beta^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{\beta x}$, $\Gamma(\alpha) = \int_0^\infty x^{\alpha-1}e^{-z}dx$, the integrating constant is $\frac{\beta^\alpha}{\Gamma(\alpha)}$
\begin{align*}
    \pi(\lambda \mid X) \propto \pi(\lambda) L(X \mid \lambda) = 4\lambda^2e^{-2\lambda} \prod_{i=1}^n \lambda e^{-\lambda X_i}  \sim Gamma(\alpha, \beta)
\end{align*}



\subsection{Markov Chain Monte Carlo}
\textbf{Motivation:} Generate a posterior distribution by running a markov chain whose equilibrium distribution is the posterior, $f(\theta \mid X)$. Required to impose "detailed balance" on the system: $\tilde{p}(x)p(x,y) = \tilde{p}(y)p(y,x)$. Achieve this through the \textit{Metropolis Algorithm:} 1) Start with harris recurrent transition density, $(q(x,y): x,y \in S)$, positive everywhere, 2) define $p(x,y) = q(x,y) \min\large (1, \frac{p(y)Q(x,y)}{p(x)Q(x,y)} \large )$

\section{Positive recurrence}
\textbf{SLLN for Markov chains:}
\begin{align*}
    \frac{1}{n}\sum_{j=1}^{n-1}I(X_j = y) \overset{a.s}{\longrightarrow} \frac{EY_1}{E\tau_1}: \, \frac{1}{n}\sum_{j=1}^{n-1}I(X_j = y) &\approx \sum_{j=0}^{N(n)}Y_j / \sum_{j=1}^{N(n)}\tau_j \textrm{, where } Y_j = \sum_{i=T_{j-1}}^{T_j - 1}I(X_j = y), \, \tau_j = T_j - T_{j-1}, \, \frac{1}{n}\sum_{j=1}^nY_j \overset{a.s}{\longrightarrow} EY_1, \, \frac{1}{n}\sum_{j=1}^n\tau_j \overset{a.s}{\longrightarrow} E\tau_1
\end{align*}
\begin{itemize}
    \item \textbf{Lyapunov method to demonstrate postivie Harris recurrence:} Must demonstrate for some $g(x) \geq 0$ and $A \subseteq S$ a) $E_x[g(X_1)] \leq g(x) - \epsilon$ for $x \in A^c$ b) $\sup_{x\in A} E_x[g(X_1)] < \infty$, c) $P_x(X_m \in \cdot) \geq \lambda \varphi(\cdot)$ for $x \in A$. Common choices of $g(x): \{x, \abs{x}^p, \log(1 + x)^p, \exp(a\abs{x}^p)\}$. Positive Harris Recurrence guarantees unique solution for stationary density of chain
    \item \textbf{General approach for element c):} $P_x(X_1 \in B) \geq \lambda \varphi(B) \Longleftrightarrow \int_Bp(x,y)dy \geq \lambda \int_B \phi(y)dy$. Then simply let $\varphi(y) = \inf_{x\in A}p(x,y) / \lambda$ and $\lambda = \int_S \inf_{x\in A} p(x,y)dy$, making sure $\lambda > 0$
    \item \textbf{Explanation of P(x, dy):} $P(x, dy) = P(x \in y + dy) \approx P(x \in [y - \Delta y/2, y + \Delta y/2]) = \int_{-\Delta y/2}^{\Delta y/2}f(x)dx \approx f(y)\Delta y \approx f(y)dy$
    \item \textbf{Markov chain positive recurrence properties:} Markov chain is positive recurrent ($E_x\pi(x) < \infty$) $\Longrightarrow \frac{1}{n}\sum_{i=0}^{n-1}r(X_i) \overset{a.s.}{\rightarrow} \sum_w \pi(x)r(w)$ and $\pi(x) = \frac{E_x\sum_{j=1}^{\tau(x)-1}I(X_j = x)}{E_x\pi(x)}$
    \item \textbf{Markov chain aperiodicity:} $\gcd\{n\geq 1 : P^n(x,x) > 0\} = 1 \Longleftrightarrow P(x,x) > \infty$
\end{itemize}

\subsection{Example: Positive Harris recurrence}
Given: $X = \{X_n: n \geq 0\}, [X_{n+1} \mid X_n = x] \sim N(\lambda x, 1 - \lambda^2)$, $\lambda \in (0,1)$ a constant. Choosing $g(x) = x^2$:
\begin{align*}
    \textrm{a) }& E_xg(X_1) = E_xX_1^2 = varX_1 + (E_xX_1)^2 = (1-\lambda^2) + (\lambda x)^2 = x^2 - (x^2 - 1)(1 - \lambda^2) \leq g(x) - 3(1 - \lambda^2) \textrm{ when } x\in K^c \, K = [-2, 2]\\
    \textrm{b) }& \sup_{x\in K}E_xg(X_1) = \sup_{x\in K}[(1-\lambda^2) + (\lambda x)^2] \leq 1 - \lambda^2 + 4\lambda^2 < \infty\\
    \textrm{c) }& P_x(X_1 \leq y) = P(N(\lambda x, 1 - \lambda^2)) = P(N(0,1) \leq \frac{y - \lambda x}{\sqrt{1 - \lambda^2}}) \Longrightarrow p.d.f: p(x,y) = \phi(\frac{y - \lambda x}{\sqrt{1 - \lambda^2}}) * \frac{1}{\sqrt{1 - \lambda^2}} > 0\\
    & \varphi(y) = \inf_{x\in K}p(x,y) / c = \inf_{x\in K} \phi(\frac{y - \lambda x}{\sqrt{1 - \lambda^2}}) * \frac{1}{c\sqrt{1 - \lambda^2}} > 0 \textrm{, since $\phi$ continuous, positive, $K$ compact} \Longrightarrow \textrm{choose} \lambda = \int_\mathbb{R} \inf_{x\in K}p(x, y)
\end{align*}
\textbf{Stationary sequence:} Noting $X_{n+1} = \lambda X_n + \epsilon_{n+1}, \, \epsilon \sim N(0, 1 - \lambda^2)$. When $X_0 \sim N(0,1) \Rightarrow X_n \sim N(0,1)$, so $N(0,1)$ is stationary distribution of $X$.

\subsection{Example: Positive Harris recurrence}
\textbf{Given:} $(Z_n:n\geq 1)$ iid positive, $\abs{EZ_1^2} < \infty$, positive continuous density, $f(\cdot)$; $X = \{X_n:n\geq 0\}$ Markov chain such that $X_{n+1} = \abs{X_n - Z_{n+1}}$\\
\textbf{Want:} Transition density, positive Harris recurrence, equilibrium density, stationary distribution, SLLN\\
\textbf{Transition density: } $P(x, dy) = P(\abs{x - Z} \in y + dy) = P(Z \in x - y + dy) + P(Z \in x + y + dy) = f(x-y)dy + f(x+y)dy$\\
\textbf{Positive Harris recurrence:}
\begin{align*}
    Z \textrm{ integrable } &\Longrightarrow \exists M \, s.t.,\, E[X \mathbb{I}(Z \leq M)] \geq (2/3)EZ, \, E[X \mathbb{I}(Z > M)] \leq (1/3) EZ \textrm{; now choose } g(x) = \abs{x} \textrm{ and define } A^c: x > M\\
    \textrm{For } x\in A^c: \, E(g(X_1)) &= E\abs{x - Z} = E(x-Z)\mathbb{I}(Z\leq x) + E(Z-x)\mathbb{I}(Z > x)\\
    &\leq x - E(Z)\mathbb{I}(Z\leq x) + E(Z)\mathbb{I}(Z > x) \leq x - (2/3)EZ + (1/3)EZ = g(x) - \epsilon \textrm{, since} EZ_1 < \infty\\
    \textrm{For } x\in A: \, P(x,dy) &\geq \inf_{x'\in[0,M]} P(x', dy) = [\inf_{x'\in[0,M]} (f(x' - y) + f(x' + y))]dy > 0 \textrm{, since $f(\cdot)$ is positive continuous} \Longrightarrow P(x,dy) \geq \lambda \varphi(y) \textrm{where $\lambda$ can be an integrating constant}
\end{align*}
\textbf{Stationary distribution:} Need to verify $\int_0^\infty P(x,dy)\pi(dx) = \pi(dy) = \pi(y)dy = \frac{P(Z_1 > y)dy}{EZ_1}$, equivalent to showing $\int_0^\infty (f(x-y) + f(x+y))P(Z > x)dx = P(Z > y)$
\begin{align*}
    \textrm{When $y=0$: }& \int_0^\infty 2f(x) \frac{P(Z_1 > x)}{EZ_1}dx = \int_0^\infty 2f(x) \frac{1 - F(x)}{EZ_1}dx = \frac{1}{EZ_1} [\frac{d}{dx}\int_0^\infty 2F(x)dx - \frac{d}{dx}\int_0^\infty 2F(x)^2dx] = \frac{2 - 1}{EZ_1} = \frac{P(Z_1 > 0)dy}{EZ_1} = \pi(0)\\
    \textrm{When $y>0$: }& \frac{d}{dy}(\int_0^\infty (f(x-y) + f(x+y))P(Z > x)dx) = \frac{d}{dy}(\int_0^\infty f(w)P(Z>w+y)dw + \int_y^\infty f(w)P(Z > w-y)dw)\\
    &= -\int_0^\infty f(w)f(w+y)dw - f(y)P(Z>0) + \int_y^\infty f(w)f(w-y)dw = -f(y) = \frac{d}{dy}(P(Z > y))
\end{align*}
\textbf{SLNN:} By stationary distribution and positive Harris recurrence, we have $\frac{1}{n}\sum_{i=1}^n f(X_i) \overset{a.s.}{\rightarrow} E_\pi f(X_0)$ and 
\begin{align*}
    E_\pi x = \int_0^\infty x\pi(x)dx = \int_0^\infty x \frac{P(Z_1 > x)}{E[Z_1]}dx = \frac{1}{EZ_1} \frac{E[Z_1^2]}{2}
\end{align*}


\subsection{Example: Positive recurrent Markov chain}
\textbf{Given:} $N_{n+1} = R_{n+1} + B_{n+1}(N_n)$, $R_1, \dots \overset{iid}{\sim} Poisson(\lambda_*)$, $(B_n(k) = Bin(k, p) : n \geq 0, k\geq 0)$\\
\textbf{Transition probability matrix:} 
\begin{align*}
    P(N_{n+1} &= y \mid N_n = x) = P(R_{n+1} = y - B_{n+1}(x)  \mid N_n = x) = \sum_{k=1}^{min(x,y)} \frac{\lambda_*^{y-k}e^{-\lambda}}{(y - k)!} P(B_{n+1}(x) = k) = \sum_{k=1}^{min(x,y)} \frac{\lambda_*^{y-k}e^{-\lambda}}{(y - k)!} \binom{x}{k}p^k(1 - p)^{x-k} 
\end{align*}
\textbf{Chain irreducible and aperiodic:} Since $P(x,y) > 0$ for all $(x,y)$ (irreducible) and $P(x,x) > 0$ for all $x$ (aperiodic)\\
\textbf{Chain positive recurrent:} Irreducible Markov chain on discrete state space is positive recurrent $\Longleftrightarrow \exists \pi \, s.t. \pi = \pi P$. We find $\pi = Poisson(\frac{\lambda_*}{1 - p})$ (not shown)
\textbf{Approximate for} $\frac{1}{n}\sum_{j=0}^{n-1}I(N_j = 0)$: $\frac{1}{n}\sum_{j=0}^{n-1}I(N_j = 0) \rightarrow \pi(0)$\\
\textbf{First transition analysis:} For $N_0 = k$, find $u(k) = E[\inf\{n\geq 1 : N_n - N_{n-1} \geq 3\} \mid N_0 = k] = E_kT$
\begin{align*}
    u(k) = E_kT = 1 + \sum_{y - x \geq 3}0 * P(k, y) + \sum_{y - x < 3} E_yTP(k,y) = 1 + \sum_{y-x<3}P(k,y)u(y)
\end{align*}

\end{document}
